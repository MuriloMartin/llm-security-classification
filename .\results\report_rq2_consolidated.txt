Confusion Matrix for gemma - few_shot:
[[307   1]
 [828 332]]
Classification Report for gemma - few_shot:
              precision    recall  f1-score   support

         sec       0.27      1.00      0.43       308
      nonsec       1.00      0.29      0.44      1160

    accuracy                           0.44      1468
   macro avg       0.63      0.64      0.44      1468
weighted avg       0.84      0.44      0.44      1468

Confusion Matrix for gemma2_27b - few_shot:
[[311   1]
 [420 747]]
Classification Report for gemma2_27b - few_shot:
              precision    recall  f1-score   support

         sec       0.43      1.00      0.60       312
      nonsec       1.00      0.64      0.78      1167

    accuracy                           0.72      1479
   macro avg       0.71      0.82      0.69      1479
weighted avg       0.88      0.72      0.74      1479

Confusion Matrix for gpt-4o-mini - few_shot:
[[309   3]
 [326 841]]
Classification Report for gpt-4o-mini - few_shot:
              precision    recall  f1-score   support

         sec       0.49      0.99      0.65       312
      nonsec       1.00      0.72      0.84      1167

    accuracy                           0.78      1479
   macro avg       0.74      0.86      0.74      1479
weighted avg       0.89      0.78      0.80      1479

Confusion Matrix for llama3 - few_shot:
[[311   1]
 [486 681]]
Classification Report for llama3 - few_shot:
              precision    recall  f1-score   support

         sec       0.39      1.00      0.56       312
      nonsec       1.00      0.58      0.74      1167

    accuracy                           0.67      1479
   macro avg       0.69      0.79      0.65      1479
weighted avg       0.87      0.67      0.70      1479

Confusion Matrix for llama3.1 - few_shot:
[[312   0]
 [554 613]]
Classification Report for llama3.1 - few_shot:
              precision    recall  f1-score   support

         sec       0.36      1.00      0.53       312
      nonsec       1.00      0.53      0.69      1167

    accuracy                           0.63      1479
   macro avg       0.68      0.76      0.61      1479
weighted avg       0.87      0.63      0.66      1479

Confusion Matrix for llama3.2-vision - few_shot:
[[310   2]
 [463 704]]
Classification Report for llama3.2-vision - few_shot:
              precision    recall  f1-score   support

         sec       0.40      0.99      0.57       312
      nonsec       1.00      0.60      0.75      1167

    accuracy                           0.69      1479
   macro avg       0.70      0.80      0.66      1479
weighted avg       0.87      0.69      0.71      1479

Confusion Matrix for mistral - few_shot:
[[312   0]
 [405 762]]
Classification Report for mistral - few_shot:
              precision    recall  f1-score   support

         sec       0.44      1.00      0.61       312
      nonsec       1.00      0.65      0.79      1167

    accuracy                           0.73      1479
   macro avg       0.72      0.83      0.70      1479
weighted avg       0.88      0.73      0.75      1479

Confusion Matrix for mistral-nemo - few_shot:
[[296  16]
 [245 922]]
Classification Report for mistral-nemo - few_shot:
              precision    recall  f1-score   support

         sec       0.55      0.95      0.69       312
      nonsec       0.98      0.79      0.88      1167

    accuracy                           0.82      1479
   macro avg       0.77      0.87      0.79      1479
weighted avg       0.89      0.82      0.84      1479

Confusion Matrix for mistral-small - few_shot:
[[310   2]
 [308 859]]
Classification Report for mistral-small - few_shot:
              precision    recall  f1-score   support

         sec       0.50      0.99      0.67       312
      nonsec       1.00      0.74      0.85      1167

    accuracy                           0.79      1479
   macro avg       0.75      0.86      0.76      1479
weighted avg       0.89      0.79      0.81      1479

Confusion Matrix for gemma - zero_shot_cot:
[[ 312    0]
 [1024  143]]
Classification Report for gemma - zero_shot_cot:
              precision    recall  f1-score   support

         sec       0.23      1.00      0.38       312
      nonsec       1.00      0.12      0.22      1167

    accuracy                           0.31      1479
   macro avg       0.62      0.56      0.30      1479
weighted avg       0.84      0.31      0.25      1479

Confusion Matrix for gemma2_27b - zero_shot_cot:
[[280   6]
 [347 778]]
Classification Report for gemma2_27b - zero_shot_cot:
              precision    recall  f1-score   support

         sec       0.45      0.98      0.61       286
      nonsec       0.99      0.69      0.82      1125

    accuracy                           0.75      1411
   macro avg       0.72      0.84      0.71      1411
weighted avg       0.88      0.75      0.77      1411

Confusion Matrix for gpt-4o-mini - zero_shot_cot:
[[307   5]
 [264 903]]
Classification Report for gpt-4o-mini - zero_shot_cot:
              precision    recall  f1-score   support

         sec       0.54      0.98      0.70       312
      nonsec       0.99      0.77      0.87      1167

    accuracy                           0.82      1479
   macro avg       0.77      0.88      0.78      1479
weighted avg       0.90      0.82      0.83      1479

Confusion Matrix for llama3 - zero_shot_cot:
[[287  12]
 [221 921]]
Classification Report for llama3 - zero_shot_cot:
              precision    recall  f1-score   support

         sec       0.56      0.96      0.71       299
      nonsec       0.99      0.81      0.89      1142

    accuracy                           0.84      1441
   macro avg       0.78      0.88      0.80      1441
weighted avg       0.90      0.84      0.85      1441

Confusion Matrix for llama3.1 - zero_shot_cot:
[[250  11]
 [228 845]]
Classification Report for llama3.1 - zero_shot_cot:
              precision    recall  f1-score   support

         sec       0.52      0.96      0.68       261
      nonsec       0.99      0.79      0.88      1073

    accuracy                           0.82      1334
   macro avg       0.76      0.87      0.78      1334
weighted avg       0.90      0.82      0.84      1334

Confusion Matrix for llama3.2-vision - zero_shot_cot:
[[213   8]
 [181 825]]
Classification Report for llama3.2-vision - zero_shot_cot:
              precision    recall  f1-score   support

         sec       0.54      0.96      0.69       221
      nonsec       0.99      0.82      0.90      1006

    accuracy                           0.85      1227
   macro avg       0.77      0.89      0.79      1227
weighted avg       0.91      0.85      0.86      1227

Confusion Matrix for mistral - zero_shot_cot:
[[299   6]
 [294 859]]
Classification Report for mistral - zero_shot_cot:
              precision    recall  f1-score   support

         sec       0.50      0.98      0.67       305
      nonsec       0.99      0.75      0.85      1153

    accuracy                           0.79      1458
   macro avg       0.75      0.86      0.76      1458
weighted avg       0.89      0.79      0.81      1458

Confusion Matrix for mistral-nemo - zero_shot_cot:
[[ 270   42]
 [ 112 1055]]
Classification Report for mistral-nemo - zero_shot_cot:
              precision    recall  f1-score   support

         sec       0.71      0.87      0.78       312
      nonsec       0.96      0.90      0.93      1167

    accuracy                           0.90      1479
   macro avg       0.83      0.88      0.86      1479
weighted avg       0.91      0.90      0.90      1479

Confusion Matrix for mistral-small - zero_shot_cot:
[[308   4]
 [266 899]]
Classification Report for mistral-small - zero_shot_cot:
              precision    recall  f1-score   support

         sec       0.54      0.99      0.70       312
      nonsec       1.00      0.77      0.87      1165

    accuracy                           0.82      1477
   macro avg       0.77      0.88      0.78      1477
weighted avg       0.90      0.82      0.83      1477

Confusion Matrix for gemma - raw_inst:
[[309   3]
 [467 700]]
Classification Report for gemma - raw_inst:
              precision    recall  f1-score   support

         sec       0.40      0.99      0.57       312
      nonsec       1.00      0.60      0.75      1167

    accuracy                           0.68      1479
   macro avg       0.70      0.80      0.66      1479
weighted avg       0.87      0.68      0.71      1479

Confusion Matrix for gemma2_27b - raw_inst:
[[ 294   18]
 [ 146 1021]]
Classification Report for gemma2_27b - raw_inst:
              precision    recall  f1-score   support

         sec       0.67      0.94      0.78       312
      nonsec       0.98      0.87      0.93      1167

    accuracy                           0.89      1479
   macro avg       0.83      0.91      0.85      1479
weighted avg       0.92      0.89      0.90      1479

Confusion Matrix for gpt-4o-mini - raw_inst:
[[ 298   14]
 [ 127 1040]]
Classification Report for gpt-4o-mini - raw_inst:
              precision    recall  f1-score   support

         sec       0.70      0.96      0.81       312
      nonsec       0.99      0.89      0.94      1167

    accuracy                           0.90      1479
   macro avg       0.84      0.92      0.87      1479
weighted avg       0.93      0.90      0.91      1479

Confusion Matrix for llama3 - raw_inst:
[[ 297   15]
 [ 156 1011]]
Classification Report for llama3 - raw_inst:
              precision    recall  f1-score   support

         sec       0.66      0.95      0.78       312
      nonsec       0.99      0.87      0.92      1167

    accuracy                           0.88      1479
   macro avg       0.82      0.91      0.85      1479
weighted avg       0.92      0.88      0.89      1479

Confusion Matrix for llama3.1 - raw_inst:
[[ 291   18]
 [ 162 1002]]
Classification Report for llama3.1 - raw_inst:
              precision    recall  f1-score   support

         sec       0.64      0.94      0.76       309
      nonsec       0.98      0.86      0.92      1164

    accuracy                           0.88      1473
   macro avg       0.81      0.90      0.84      1473
weighted avg       0.91      0.88      0.89      1473

Confusion Matrix for llama3.2-vision - raw_inst:
[[295  16]
 [170 992]]
Classification Report for llama3.2-vision - raw_inst:
              precision    recall  f1-score   support

         sec       0.63      0.95      0.76       311
      nonsec       0.98      0.85      0.91      1162

    accuracy                           0.87      1473
   macro avg       0.81      0.90      0.84      1473
weighted avg       0.91      0.87      0.88      1473

Confusion Matrix for mistral - raw_inst:
[[ 274   38]
 [  83 1084]]
Classification Report for mistral - raw_inst:
              precision    recall  f1-score   support

         sec       0.77      0.88      0.82       312
      nonsec       0.97      0.93      0.95      1167

    accuracy                           0.92      1479
   macro avg       0.87      0.90      0.88      1479
weighted avg       0.92      0.92      0.92      1479

Confusion Matrix for mistral-nemo - raw_inst:
[[ 246   66]
 [  55 1112]]
Classification Report for mistral-nemo - raw_inst:
              precision    recall  f1-score   support

         sec       0.82      0.79      0.80       312
      nonsec       0.94      0.95      0.95      1167

    accuracy                           0.92      1479
   macro avg       0.88      0.87      0.88      1479
weighted avg       0.92      0.92      0.92      1479

Confusion Matrix for mistral-small - raw_inst:
[[ 293   19]
 [ 137 1030]]
Classification Report for mistral-small - raw_inst:
              precision    recall  f1-score   support

         sec       0.68      0.94      0.79       312
      nonsec       0.98      0.88      0.93      1167

    accuracy                           0.89      1479
   macro avg       0.83      0.91      0.86      1479
weighted avg       0.92      0.89      0.90      1479

